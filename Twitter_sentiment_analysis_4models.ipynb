{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:03.412102Z",
     "iopub.status.busy": "2021-12-23T00:42:03.410754Z",
     "iopub.status.idle": "2021-12-23T00:42:05.346163Z",
     "shell.execute_reply": "2021-12-23T00:42:05.346682Z",
     "shell.execute_reply.started": "2021-12-22T19:49:09.39204Z"
    },
    "papermill": {
     "duration": 1.970682,
     "end_time": "2021-12-23T00:42:05.347035",
     "exception": false,
     "start_time": "2021-12-23T00:42:03.376353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:05.413637Z",
     "iopub.status.busy": "2021-12-23T00:42:05.412939Z",
     "iopub.status.idle": "2021-12-23T00:42:05.664692Z",
     "shell.execute_reply": "2021-12-23T00:42:05.665336Z",
     "shell.execute_reply.started": "2021-12-22T19:49:11.569464Z"
    },
    "papermill": {
     "duration": 0.287498,
     "end_time": "2021-12-23T00:42:05.665517",
     "exception": false,
     "start_time": "2021-12-23T00:42:05.378019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_E6oV3lV.csv')\n",
    "test = pd.read_csv('test_tweets_anuFYb8.csv')\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:05.737433Z",
     "iopub.status.busy": "2021-12-23T00:42:05.734921Z",
     "iopub.status.idle": "2021-12-23T00:42:05.740728Z",
     "shell.execute_reply": "2021-12-23T00:42:05.741302Z",
     "shell.execute_reply.started": "2021-12-22T19:49:11.79194Z"
    },
    "papermill": {
     "duration": 0.041396,
     "end_time": "2021-12-23T00:42:05.741478",
     "exception": false,
     "start_time": "2021-12-23T00:42:05.700082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training set: (31962, 3)\n",
      "Shape of Testing set: (17197, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shape of Training set:\", train.shape)\n",
    "print(\"Shape of Testing set:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:05.826908Z",
     "iopub.status.busy": "2021-12-23T00:42:05.826170Z",
     "iopub.status.idle": "2021-12-23T00:42:05.846174Z",
     "shell.execute_reply": "2021-12-23T00:42:05.845467Z",
     "shell.execute_reply.started": "2021-12-22T19:49:11.80045Z"
    },
    "papermill": {
     "duration": 0.069297,
     "end_time": "2021-12-23T00:42:05.846337",
     "exception": false,
     "start_time": "2021-12-23T00:42:05.777040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train unique: (29530, 4)\n"
     ]
    }
   ],
   "source": [
    "train.drop_duplicates(subset=['tweet'], keep='last', inplace=True)\n",
    "train.reset_index(inplace=True)\n",
    "print(\"Shape of Train unique:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:05.912532Z",
     "iopub.status.busy": "2021-12-23T00:42:05.911547Z",
     "iopub.status.idle": "2021-12-23T00:42:08.045749Z",
     "shell.execute_reply": "2021-12-23T00:42:08.045199Z",
     "shell.execute_reply.started": "2021-12-22T19:49:11.840688Z"
    },
    "papermill": {
     "duration": 2.168389,
     "end_time": "2021-12-23T00:42:08.045944",
     "exception": false,
     "start_time": "2021-12-23T00:42:05.877555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[train['tweet'].map(lambda x: x.isascii())]\n",
    "test[test['tweet'].map(lambda x: x.isascii())]\n",
    "#Dataclean\n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+','',text) \n",
    "    text = re.sub(r'#','',text)                  \n",
    "    text = re.sub(r'RT[\\s]+',' ',text)           \n",
    "    text = re.sub(r'\\n','',text) \n",
    "    text = re.sub(r',','',text) \n",
    "    text = re.sub(r'.[.]+','',text) \n",
    "    text = re.sub(r'\\w+:\\/\\/\\S+','',text) \n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)  \n",
    "    text = re.sub(r'/',' ',text)\n",
    "    text = re.sub(r'-',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'!','',text)\n",
    "    text = re.sub(r':',' ',text)\n",
    "    text = re.sub(r'$','',text)\n",
    "    text = re.sub(r'%','',text)\n",
    "    text = re.sub(r'^','',text)\n",
    "    text = re.sub(r'&','',text)\n",
    "    text = re.sub(r'=',' ',text)\n",
    "    text = re.sub(r' +',' ',text) \n",
    "    return text\n",
    "\n",
    "def clean_emojis(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(clean_tweets)  \n",
    "train['tweet'] = train['tweet'].apply(clean_emojis)  \n",
    "train['tweet'] = train.tweet.str.lower()  \n",
    "train['tweet'] = train['tweet'].str.strip()  \n",
    "test['tweet'] = test['tweet'].apply(clean_tweets)  \n",
    "test['tweet'] = test['tweet'].apply(clean_emojis) \n",
    "test['tweet'] = test.tweet.str.lower()   \n",
    "test['tweet'] = test['tweet'].str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.118893Z",
     "iopub.status.busy": "2021-12-23T00:42:08.118213Z",
     "iopub.status.idle": "2021-12-23T00:42:08.121911Z",
     "shell.execute_reply": "2021-12-23T00:42:08.121373Z",
     "shell.execute_reply.started": "2021-12-22T19:49:13.941759Z"
    },
    "papermill": {
     "duration": 0.044031,
     "end_time": "2021-12-23T00:42:08.122049",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.078018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for lyft credit i can't use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2 2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id  label                                              tweet\n",
       "0      0   1      0  when a father is dysfunctional and is so selfi...\n",
       "1      1   2      0  thanks for lyft credit i can't use cause they ...\n",
       "2      2   3      0                                bihday your majesty\n",
       "3      4   5      0                  factsguide society now motivation\n",
       "4      5   6      0  [2 2] huge fan fare and big talking before the..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.191929Z",
     "iopub.status.busy": "2021-12-23T00:42:08.186323Z",
     "iopub.status.idle": "2021-12-23T00:42:08.195628Z",
     "shell.execute_reply": "2021-12-23T00:42:08.195124Z",
     "shell.execute_reply.started": "2021-12-22T19:49:13.955772Z"
    },
    "papermill": {
     "duration": 0.043006,
     "end_time": "2021-12-23T00:42:08.195759",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.152753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>white supremacists want everyone to see the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your acne altwaystoheal heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  studiolife aislife requires passion dedication...\n",
       "1  31964  white supremacists want everyone to see the ne...\n",
       "2  31965  safe ways to heal your acne altwaystoheal heal...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967  3rd bihday to my amazing hilarious nephew eli ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.276212Z",
     "iopub.status.busy": "2021-12-23T00:42:08.263398Z",
     "iopub.status.idle": "2021-12-23T00:42:08.280387Z",
     "shell.execute_reply": "2021-12-23T00:42:08.279875Z",
     "shell.execute_reply.started": "2021-12-22T19:49:13.970165Z"
    },
    "papermill": {
     "duration": 0.052188,
     "end_time": "2021-12-23T00:42:08.280522",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.228334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so selfish he drags his kids into his dysfunctio run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for lyft credit i can't use cause they don't offer wheelchair vans in pd disapointed getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2 2] huge fan fare and big talking before they leav chaos and pay disputes when they get ther allshowandnogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29525</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate isz that youuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisol shame imwithher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29528</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>sikh temple vandalised in in calgary wso condemns act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29529</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29530 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "0          1      0   \n",
       "1          2      0   \n",
       "2          3      0   \n",
       "3          5      0   \n",
       "4          6      0   \n",
       "...      ...    ...   \n",
       "29525  31958      0   \n",
       "29526  31959      0   \n",
       "29527  31960      0   \n",
       "29528  31961      1   \n",
       "29529  31962      0   \n",
       "\n",
       "                                                                                                                               tweet  \n",
       "0                                         when a father is dysfunctional and is so selfish he drags his kids into his dysfunctio run  \n",
       "1                             thanks for lyft credit i can't use cause they don't offer wheelchair vans in pd disapointed getthanked  \n",
       "2                                                                                                                bihday your majesty  \n",
       "3                                                                                                  factsguide society now motivation  \n",
       "4                      [2 2] huge fan fare and big talking before they leav chaos and pay disputes when they get ther allshowandnogo  \n",
       "...                                                                                                                              ...  \n",
       "29525                                                                                                            ate isz that youuu?  \n",
       "29526  to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisol shame imwithher  \n",
       "29527                                                                  listening to sad songs on a monday morning otw to work is sad  \n",
       "29528                                                                          sikh temple vandalised in in calgary wso condemns act  \n",
       "29529                                                                                                       thank you for you follow  \n",
       "\n",
       "[29530 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1---> Bad/sexist/racist tweet\n",
    "0---> Regular tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.420616Z",
     "iopub.status.busy": "2021-12-23T00:42:08.419958Z",
     "iopub.status.idle": "2021-12-23T00:42:08.425286Z",
     "shell.execute_reply": "2021-12-23T00:42:08.425940Z",
     "shell.execute_reply.started": "2021-12-22T19:49:13.992308Z"
    },
    "papermill": {
     "duration": 0.047881,
     "end_time": "2021-12-23T00:42:08.426161",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.378280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (29530, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    27517\n",
       "1     2013\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset shape: \", df.shape)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032329,
     "end_time": "2021-12-23T00:42:08.557236",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.524907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Cleaning Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.628026Z",
     "iopub.status.busy": "2021-12-23T00:42:08.627071Z",
     "iopub.status.idle": "2021-12-23T00:42:08.630998Z",
     "shell.execute_reply": "2021-12-23T00:42:08.630392Z",
     "shell.execute_reply.started": "2021-12-22T19:49:14.004277Z"
    },
    "papermill": {
     "duration": 0.041248,
     "end_time": "2021-12-23T00:42:08.631129",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.589881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.702043Z",
     "iopub.status.busy": "2021-12-23T00:42:08.701079Z",
     "iopub.status.idle": "2021-12-23T00:42:08.834592Z",
     "shell.execute_reply": "2021-12-23T00:42:08.835112Z",
     "shell.execute_reply.started": "2021-12-22T19:49:14.015799Z"
    },
    "papermill": {
     "duration": 0.170804,
     "end_time": "2021-12-23T00:42:08.835293",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.664489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].astype(str)\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032178,
     "end_time": "2021-12-23T00:42:08.900676",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.868498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Cleaning Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:08.973516Z",
     "iopub.status.busy": "2021-12-23T00:42:08.972492Z",
     "iopub.status.idle": "2021-12-23T00:42:09.807950Z",
     "shell.execute_reply": "2021-12-23T00:42:09.808708Z",
     "shell.execute_reply.started": "2021-12-22T19:49:14.156088Z"
    },
    "papermill": {
     "duration": 0.875627,
     "end_time": "2021-12-23T00:42:09.808933",
     "exception": false,
     "start_time": "2021-12-23T00:42:08.933306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033422,
     "end_time": "2021-12-23T00:42:09.876193",
     "exception": false,
     "start_time": "2021-12-23T00:42:09.842771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Cleaning Numeric numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:09.946494Z",
     "iopub.status.busy": "2021-12-23T00:42:09.945562Z",
     "iopub.status.idle": "2021-12-23T00:42:10.062805Z",
     "shell.execute_reply": "2021-12-23T00:42:10.062233Z",
     "shell.execute_reply.started": "2021-12-22T19:49:14.995812Z"
    },
    "papermill": {
     "duration": 0.153432,
     "end_time": "2021-12-23T00:42:10.062963",
     "exception": false,
     "start_time": "2021-12-23T00:42:09.909531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "df['tweet'] = df['tweet'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033999,
     "end_time": "2021-12-23T00:42:10.130325",
     "exception": false,
     "start_time": "2021-12-23T00:42:10.096326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Tokenizing Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:10.204016Z",
     "iopub.status.busy": "2021-12-23T00:42:10.203364Z",
     "iopub.status.idle": "2021-12-23T00:42:14.956721Z",
     "shell.execute_reply": "2021-12-23T00:42:14.956157Z",
     "shell.execute_reply.started": "2021-12-22T19:49:15.117053Z"
    },
    "papermill": {
     "duration": 4.793253,
     "end_time": "2021-12-23T00:42:14.956876",
     "exception": false,
     "start_time": "2021-12-23T00:42:10.163623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, dysfunctio, run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, lyft, credit, cant, use, cause, dont, offer, wheelchair, vans, pd, disapointed, getthanked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[huge, fan, fare, big, talking, leav, chaos, pay, disputes, get, ther, allshowandnogo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   5      0   \n",
       "4   6      0   \n",
       "\n",
       "                                                                                                  tweet  \n",
       "0                                        [father, dysfunctional, selfish, drags, kids, dysfunctio, run]  \n",
       "1  [thanks, lyft, credit, cant, use, cause, dont, offer, wheelchair, vans, pd, disapointed, getthanked]  \n",
       "2                                                                                     [bihday, majesty]  \n",
       "3                                                                     [factsguide, society, motivation]  \n",
       "4                [huge, fan, fare, big, talking, leav, chaos, pay, disputes, get, ther, allshowandnogo]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming requires tokens, hence convertting tweets into Tokens\n",
    "tokens = (word_tokenize(i) for i in df.tweet)\n",
    "df['tweet'] = df['tweet'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03409,
     "end_time": "2021-12-23T00:42:15.025060",
     "exception": false,
     "start_time": "2021-12-23T00:42:14.990970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:15.146410Z",
     "iopub.status.busy": "2021-12-23T00:42:15.130754Z",
     "iopub.status.idle": "2021-12-23T00:42:19.226899Z",
     "shell.execute_reply": "2021-12-23T00:42:19.226359Z",
     "shell.execute_reply.started": "2021-12-22T19:49:19.809434Z"
    },
    "papermill": {
     "duration": 4.167736,
     "end_time": "2021-12-23T00:42:19.227046",
     "exception": false,
     "start_time": "2021-12-23T00:42:15.059310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemm = SnowballStemmer('english')\n",
    "df['tweet'] = df['tweet'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033951,
     "end_time": "2021-12-23T00:42:19.295136",
     "exception": false,
     "start_time": "2021-12-23T00:42:19.261185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Splitting data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:19.451169Z",
     "iopub.status.busy": "2021-12-23T00:42:19.365800Z",
     "iopub.status.idle": "2021-12-23T00:42:19.462554Z",
     "shell.execute_reply": "2021-12-23T00:42:19.461736Z",
     "shell.execute_reply.started": "2021-12-22T19:49:23.904821Z"
    },
    "papermill": {
     "duration": 0.133699,
     "end_time": "2021-12-23T00:42:19.462725",
     "exception": false,
     "start_time": "2021-12-23T00:42:19.329026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['tweet'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "y = df['label'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3) # random_state=3 because 3 is my favourite number :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036864,
     "end_time": "2021-12-23T00:42:23.312061",
     "exception": false,
     "start_time": "2021-12-23T00:42:23.275197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Transforming to TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03658,
     "end_time": "2021-12-23T00:42:23.386175",
     "exception": false,
     "start_time": "2021-12-23T00:42:23.349595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Fitting the Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.036571,
     "end_time": "2021-12-23T00:42:23.459522",
     "exception": false,
     "start_time": "2021-12-23T00:42:23.422951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  154719\n"
     ]
    }
   ],
   "source": [
    "vectoriser = CountVectorizer(ngram_range=(1,2))\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036579,
     "end_time": "2021-12-23T00:42:23.533240",
     "exception": false,
     "start_time": "2021-12-23T00:42:23.496661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Fitting the TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:23.610718Z",
     "iopub.status.busy": "2021-12-23T00:42:23.609724Z",
     "iopub.status.idle": "2021-12-23T00:42:25.038135Z",
     "shell.execute_reply": "2021-12-23T00:42:25.037563Z",
     "shell.execute_reply.started": "2021-12-22T19:49:27.662334Z"
    },
    "papermill": {
     "duration": 1.468193,
     "end_time": "2021-12-23T00:42:25.038279",
     "exception": false,
     "start_time": "2021-12-23T00:42:23.570086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  154719\n"
     ]
    }
   ],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03758,
     "end_time": "2021-12-23T00:42:25.113161",
     "exception": false,
     "start_time": "2021-12-23T00:42:25.075581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Transforming the data using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:25.191808Z",
     "iopub.status.busy": "2021-12-23T00:42:25.191205Z",
     "iopub.status.idle": "2021-12-23T00:42:26.063948Z",
     "shell.execute_reply": "2021-12-23T00:42:26.064471Z",
     "shell.execute_reply.started": "2021-12-22T19:49:29.105101Z"
    },
    "papermill": {
     "duration": 0.913295,
     "end_time": "2021-12-23T00:42:26.064637",
     "exception": false,
     "start_time": "2021-12-23T00:42:25.151342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:26.142700Z",
     "iopub.status.busy": "2021-12-23T00:42:26.142072Z",
     "iopub.status.idle": "2021-12-23T00:42:26.149950Z",
     "shell.execute_reply": "2021-12-23T00:42:26.150385Z",
     "shell.execute_reply.started": "2021-12-22T19:49:29.999058Z"
    },
    "papermill": {
     "duration": 0.048764,
     "end_time": "2021-12-23T00:42:26.150576",
     "exception": false,
     "start_time": "2021-12-23T00:42:26.101812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using 4 models\n",
    "models = {\n",
    "    \n",
    "    'SVC' :{\n",
    "        'model' : SVC(),\n",
    "        'parameters' : {\n",
    "            'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'logistics_regression' :{\n",
    "        'model' : LogisticRegression(solver = 'lbfgs', multi_class = 'auto'),\n",
    "        'parameters' : {\n",
    "            'C' : [0.1, 1, 10, 50, 60, 90, 100], 'solver' : ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'MultinomialNB' :{\n",
    "        'model' : MultinomialNB(),\n",
    "        'parameters' : {\n",
    "            'alpha' : np.linspace(0.5, 1.5, 6), 'fit_prior' : [True, False]\n",
    "        }\n",
    "    },\n",
    "        \n",
    "    'random_forest' :{\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'parameters' : {\n",
    "            'n_estimators' : [80,85,90,95,100], \n",
    "            'max_depth':[20,30,None], 'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T00:42:26.228201Z",
     "iopub.status.busy": "2021-12-23T00:42:26.227553Z",
     "iopub.status.idle": "2021-12-23T04:41:59.304045Z",
     "shell.execute_reply": "2021-12-23T04:41:59.303401Z"
    },
    "papermill": {
     "duration": 14373.116521,
     "end_time": "2021-12-23T04:41:59.304196",
     "exception": false,
     "start_time": "2021-12-23T00:42:26.187675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "\n",
      "Fitting...1\n",
      "[[5376  114]\n",
      " [ 142  274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5490\n",
      "           1       0.71      0.66      0.68       416\n",
      "\n",
      "    accuracy                           0.96      5906\n",
      "   macro avg       0.84      0.82      0.83      5906\n",
      "weighted avg       0.96      0.96      0.96      5906\n",
      "\n",
      "\n",
      "The score is appended to the list...\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "\n",
      "Fitting...1\n",
      "[[5426   64]\n",
      " [ 173  243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5490\n",
      "           1       0.79      0.58      0.67       416\n",
      "\n",
      "    accuracy                           0.96      5906\n",
      "   macro avg       0.88      0.79      0.83      5906\n",
      "weighted avg       0.96      0.96      0.96      5906\n",
      "\n",
      "\n",
      "The score is appended to the list...\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Fitting...\n",
      "\n",
      "Fitting...1\n",
      "[[5490    0]\n",
      " [ 367   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      5490\n",
      "           1       1.00      0.12      0.21       416\n",
      "\n",
      "    accuracy                           0.94      5906\n",
      "   macro avg       0.97      0.56      0.59      5906\n",
      "weighted avg       0.94      0.94      0.91      5906\n",
      "\n",
      "\n",
      "The score is appended to the list...\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "\n",
      "Fitting...1\n",
      "[[5458   32]\n",
      " [ 236  180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      5490\n",
      "           1       0.85      0.43      0.57       416\n",
      "\n",
      "    accuracy                           0.95      5906\n",
      "   macro avg       0.90      0.71      0.77      5906\n",
      "weighted avg       0.95      0.95      0.95      5906\n",
      "\n",
      "\n",
      "The score is appended to the list...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_accuracy</th>\n",
       "      <th>best_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.956654</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.959871</td>\n",
       "      <td>{'C': 100, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.937860</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.954622</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 95}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_accuracy  \\\n",
       "0                   SVC       0.956654   \n",
       "1  logistics_regression       0.959871   \n",
       "2         MultinomialNB       0.937860   \n",
       "3         random_forest       0.954622   \n",
       "\n",
       "                                                best_parameters  \n",
       "0                    {'C': 10, 'gamma': 1, 'kernel': 'sigmoid'}  \n",
       "1                                 {'C': 100, 'solver': 'lbfgs'}  \n",
       "2                             {'alpha': 0.5, 'fit_prior': True}  \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 95}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for model_name, mp in models.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['parameters'], cv=5, n_jobs=-1)\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    print('\\nFitting...1')\n",
    "    clf_pred = best_model.predict(X_test)\n",
    "    \n",
    "    #confusion matrix\n",
    "    print(confusion_matrix(y_test,clf_pred))\n",
    "    print(metrics.classification_report(y_test, clf_pred))\n",
    "    score.append({\n",
    "        'model' : model_name,\n",
    "        'best_accuracy' : best_model.score(X_test, y_test),\n",
    "        'best_parameters' : clf.best_params_\n",
    "    })\n",
    "    print('\\nThe score is appended to the list...\\n')\n",
    "    \n",
    "res = pd.DataFrame(score, columns=['model', 'best_accuracy', 'best_parameters'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048535,
     "end_time": "2021-12-23T04:41:59.487335",
     "exception": false,
     "start_time": "2021-12-23T04:41:59.438800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043554,
     "end_time": "2021-12-23T04:41:59.575204",
     "exception": false,
     "start_time": "2021-12-23T04:41:59.531650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14405.849234,
   "end_time": "2021-12-23T04:42:01.219271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-23T00:41:55.370037",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
